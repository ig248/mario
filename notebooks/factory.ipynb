{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Better FunctionTransformer\n",
    "In an attempt to simplify building machine learning pipelines in Python, I found myself tearing into the fundamental fabric of the language such as metaclasses. If something seems cumbersome, there must be a better way! (Though it might take some effort to find it!)\n",
    "\n",
    "## Pipelines and parameters\n",
    "One of the most convenient features in `scikit-learn` is the ability to build complex models by chaining transformers and estimators into pipelines, as well as access and set (hyper-)parameters *after* the transformer (or pipeline) is initialized.\n",
    "\n",
    "Let us create a simple pipeline with a single step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and put it through the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.22474487, -1.22474487],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 1.22474487,  1.22474487]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us inspect the parameters of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and change some of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61237244, 1.22474487],\n",
       "       [1.83711731, 2.44948974],\n",
       "       [3.06186218, 3.67423461]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.set_params(scaler__with_mean=False)\n",
    "# or:\n",
    "pipeline.named_steps['scaler'].set_params(with_mean=False)\n",
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mechanism is hugely useful for saving models or performing search over parameters, e.g. for cross-validation.\n",
    "\n",
    "## Custom transformers\n",
    "What if we want to apply a custom function? Let's consider a simple stateless transform (i.e. one that does not need to store any fitted parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale(x, factor=1.):\n",
    "    \"\"\"Scale array x by given factor\"\"\"\n",
    "    return x * factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap this in a pipeline, we can use the built-in `FunctionTransformer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/igor/.pyenv/versions/3.6.4/envs/mario/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/igor/.pyenv/versions/3.6.4/envs/mario/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', FunctionTransformer(scale))\n",
    "])\n",
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we change the `factor` parameter? `get_params` is suddenly much less useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "             func=<function scale at 0x118b96730>, inv_kw_args=None,\n",
       "             inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "             validate=None))],\n",
       " 'scaler': FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "           func=<function scale at 0x118b96730>, inv_kw_args=None,\n",
       "           inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "           validate=None),\n",
       " 'scaler__accept_sparse': False,\n",
       " 'scaler__check_inverse': True,\n",
       " 'scaler__func': <function __main__.scale(x, factor=1.0)>,\n",
       " 'scaler__inv_kw_args': None,\n",
       " 'scaler__inverse_func': None,\n",
       " 'scaler__kw_args': None,\n",
       " 'scaler__pass_y': 'deprecated',\n",
       " 'scaler__validate': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need is `FunctionTransformer`'s parameter `kw_args`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/igor/.pyenv/versions/3.6.4/envs/mario/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/igor/.pyenv/versions/3.6.4/envs/mario/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  4.],\n",
       "       [ 6.,  8.],\n",
       "       [10., 12.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline.set_params(scaler__factor=2.) # raises ValueError\n",
    "pipeline.set_params(scaler__kw_args={'factor': 2.})\n",
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not especially elegant, but we can wrap it up in an object that behaves just like a nativ transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ScaleTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom scaling transformer\"\"\"\n",
    "    def __init__(self, factor=1.):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return scale(X, factor=self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  4.],\n",
       "       [ 6.,  8.],\n",
       "       [10., 12.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', ScaleTransformer())\n",
    "])\n",
    "pipeline.set_params(scaler__factor=2.)\n",
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magic goes on under the hood: `Pipeline` inspects the `__init__` method of the transformer to determine what parameters are available. However, writing all this boilerplate for each parametric function seems repetetive and outright un-pythonic.\n",
    "\n",
    "What I wanted was a *tranformer factory*, which can construct the equivalent transformer *class* (or *instance*) from the function alone, along the lines of:\n",
    "\n",
    "```python\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', BetterFunctionTansformer(scale))\n",
    "])\n",
    "\n",
    "pipeline.set_params(scaler__factor=2.)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamically created transformer class\n",
    "To create our transformer with desired properties dynamically, we need to solve three problems:\n",
    "1. Determine the signature of the input function\n",
    "2. Create functions for class methods `__init__`, `fit`, `transform`\n",
    "3. Create the transformer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the function signature\n",
    "Using `inspect.signature`, we get the function name, function args, kwargs and their default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "signature = inspect.signature(func)\n",
    "args = [name for name, param in signature.parameters.items() if param.default is inspect._empty]\n",
    "kwargs_defaults = [(name, param.default) for name, param in signature.parameters.items() if param.default is not inspect._empty]\n",
    "kwargs, defaults = zip(*kwargs_defaults)\n",
    "all_args = list(args) + list(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('scale', 'Scale array x by given factor')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.__name__, func.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['x', 'factor'], ['x'], ('factor',), (1.0,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_args, args, kwargs, defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the class methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from decorator import FunctionMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_signature = '__init__(self, {args})'.format(args=', '.join(kwargs))\n",
    "init_kwarg_string = '\\n'.join(['self.{kwarg}={kwarg}'.format(kwarg=kwarg) for kwarg in kwargs])\n",
    "init_body = \"\"\"self.func = func\n",
    "{init_kwarg_string}\"\"\".format(init_kwarg_string=init_kwarg_string)\n",
    "\n",
    "proto__init = FunctionMaker.create(init_signature, init_body, {'func': func}, defaults=defaults)\n",
    "proto_fit = FunctionMaker.create('fit(self, x)', 'return self', {})\n",
    "\n",
    "kwarg_string = ', '.join(['{kwarg}=self.{kwarg}'.format(kwarg=kwarg) for kwarg in kwargs])\n",
    "transform_body = 'return self.func(x, {kwarg_string})'.format(kwarg_string=kwarg_string)\n",
    "proto_transform = FunctionMaker.create('transform(self, x)', transform_body, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proto_dict = {\n",
    "    '__init__': proto__init,\n",
    "    'fit': proto_fit,\n",
    "    'transform': proto_transform\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the new class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "new_class = type('FunctionTransformer_'+func.__name__, (BaseEstimator, TransformerMixin), proto_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transformer = new_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voila!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factor': 1.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transformer.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTransformer_scale(factor=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transformer.set_params(factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  6.],\n",
       "       [ 9., 12.],\n",
       "       [15., 18.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together, I arrived at the code in `sklearn_transformer_factory.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mario.factory.transformer_factory import make_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10., 20.],\n",
       "       [30., 40.],\n",
       "       [50., 60.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('identity', make_transformer()),\n",
    "    ('scaler', make_transformer(scale, factor=2))\n",
    "])\n",
    "pipeline.set_params(scaler__factor=10)\n",
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
