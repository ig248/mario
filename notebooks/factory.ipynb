{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better custom transformers in ML pipelines\n",
    "\n",
    "One of the most convenient features in `scikit-learn` is the ability to build complex models by chaining transformers and estimators into pipelines.\n",
    "\n",
    "![Optimus Prime](optimus-thumb.png)\n",
    "\n",
    "\n",
    "Importantly, all (hyper-)parameters of each transformer remain accessible and *tunable*. The simplicity suffers somewhat once we need to add custom preprocessing functions into the pipeline. The \"standard\" approach using [`sklearn.preprocessing.FunctionTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) felt decidedly unsatisfactory once I tried to define some parameter search spaces, so I looked into implementing a more usable alternative:\n",
    "\n",
    "> Beautiful is better than ugly!\n",
    "\n",
    "<!--more-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example and motivation\n",
    "\n",
    "The pipeline approach simplifies model selection (including hyperparameter tuning), provides a simple way\n",
    "to persist models, and thus solves many deployment and reproducibility issues.\n",
    "\n",
    "`scikit-learn` provides a wide range of transformers for common data preprocessing tasks. Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1., 2.],\n",
    "    [3., 4.],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and put it through the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us inspect the parameters of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and change some of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.set_params(scaler__with_mean=False)\n",
    "# or:\n",
    "pipeline.named_steps['scaler'].set_params(with_mean=False)\n",
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mechanism is hugely useful for saving models or performing search over parameters, e.g. for cross-validation. A search grid could be specified as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'scaler__with_mean': [True, False],\n",
    "    'scaler__with_std': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem with `FunctionTransformer`\n",
    "What if we want to apply a custom function? Let's consider a simple stateless transform (i.e. one that does not need to store any fitted parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale(x, factor=1.):\n",
    "    \"\"\"Scale array by given factor.\"\"\"\n",
    "    return x * factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap this in a pipeline, we can use the built-in `FunctionTransformer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/igor/.pyenv/versions/3.6.4/envs/mario/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/igor/.pyenv/versions/3.6.4/envs/mario/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', FunctionTransformer(scale))\n",
    "])\n",
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we change the `factor` parameter? `get_params` is suddenly much less useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "             func=<function scale at 0x11c4db6a8>, inv_kw_args=None,\n",
       "             inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "             validate=None))],\n",
       " 'scaler': FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "           func=<function scale at 0x11c4db6a8>, inv_kw_args=None,\n",
       "           inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "           validate=None),\n",
       " 'scaler__accept_sparse': False,\n",
       " 'scaler__check_inverse': True,\n",
       " 'scaler__func': <function __main__.scale(x, factor=1.0)>,\n",
       " 'scaler__inv_kw_args': None,\n",
       " 'scaler__inverse_func': None,\n",
       " 'scaler__kw_args': None,\n",
       " 'scaler__pass_y': 'deprecated',\n",
       " 'scaler__validate': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are forced to use is `FunctionTransformer`'s catch-all `kw_args`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/igor/.pyenv/versions/3.6.4/envs/mario/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/Users/igor/.pyenv/versions/3.6.4/envs/mario/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2., 4.],\n",
       "       [6., 8.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.set_params(scaler__kw_args={'factor': 2.})\n",
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to perform a hyperparameter search, we would need to define a grid in a rather cumbersome way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'scaler__kw_args': [{'factor': 1.}, {'factor': 2.}]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, we lose the ability to factorize the search space.\n",
    "\n",
    "Alternatively, we can wrap our function in an custom transformer class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ScaleTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom scaling transformer\"\"\"\n",
    "    def __init__(self, factor=1.):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return scale(X, factor=self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 4.],\n",
       "       [6., 8.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', ScaleTransformer())\n",
    "])\n",
    "pipeline.set_params(scaler__factor=2.)\n",
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magic goes on under the hood: `Pipeline` inspects the `__init__` method of the transformer to determine what parameters are available. However, writing all this boilerplate for each parametric function seems repetetive and outright un-pythonic.\n",
    "\n",
    "What I wanted was a *tranformer factory*, which can construct the equivalent transformer *class* (or *instance*) from the function alone, along the lines of:\n",
    "\n",
    "```python\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', function_transformer(scale))\n",
    "])\n",
    "\n",
    "pipeline.set_params(scaler__factor=2.)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating custom transformers dynamically\n",
    "\n",
    "To create our transformer with desired properties dynamically, we need to solve three problems:\n",
    "1. Determine the signature of the input function\n",
    "2. Create functions for class methods `__init__`, `fit`, `transform`\n",
    "3. Create the transformer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the function signature\n",
    "Using the all-powerfull `inspect` module, we can get the function name, function args, kwargs, and their default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "signature = inspect.signature(func)\n",
    "args = [name for name, param in signature.parameters.items() if param.default is inspect._empty]\n",
    "kwargs_defaults = [(name, param.default) for name, param in signature.parameters.items() if param.default is not inspect._empty]\n",
    "kwargs, defaults = zip(*kwargs_defaults)\n",
    "all_args = list(args) + list(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('scale', 'Scale array by given factor.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.__name__, func.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['x', 'factor'], ['x'], ('factor',), (1.0,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_args, args, kwargs, defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the class methods\n",
    "\n",
    "Unfortunately, the only way to create the class methods seems to rely on `eval` - the `FunctionMaker` from the `decorator` module provides ome respite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from decorator import FunctionMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_signature = '__init__(self, {args})'.format(args=', '.join(kwargs))\n",
    "init_kwarg_string = '\\n'.join(['self.{kwarg}={kwarg}'.format(kwarg=kwarg) for kwarg in kwargs])\n",
    "init_body = \"\"\"self.func = func\n",
    "{init_kwarg_string}\"\"\".format(init_kwarg_string=init_kwarg_string)\n",
    "\n",
    "proto__init = FunctionMaker.create(init_signature, init_body, {'func': func}, defaults=defaults)\n",
    "proto_fit = FunctionMaker.create('fit(self, x)', 'return self', {})\n",
    "\n",
    "kwarg_string = ', '.join(['{kwarg}=self.{kwarg}'.format(kwarg=kwarg) for kwarg in kwargs])\n",
    "transform_body = 'return self.func(x, {kwarg_string})'.format(kwarg_string=kwarg_string)\n",
    "proto_transform = FunctionMaker.create('transform(self, x)', transform_body, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proto_dict = {\n",
    "    '__doc__': func.__doc__,\n",
    "    '__init__': proto__init,\n",
    "    'fit': proto_fit,\n",
    "    'transform': proto_transform\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the new class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "new_class = type('FunctionTransformer_'+func.__name__, (BaseEstimator, TransformerMixin), proto_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transformer = new_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        FunctionTransformer_scale\n",
       "\u001b[0;31mString form:\u001b[0m FunctionTransformer_scale(factor=1.0)\n",
       "\u001b[0;31mDocstring:\u001b[0m   Scale array by given factor.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??new_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scale array by given factor.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transformer.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factor': 1.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transformer.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTransformer_scale(factor=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transformer.set_params(factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  6.],\n",
       "       [ 9., 12.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together, I arrived at the implementation found [here](https://github.com/ig248/mario/blob/master/mario/factory/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from mario.factory import function_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10., 20.],\n",
       "       [30., 40.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('identity', function_transformer()),\n",
    "    ('scaler', function_transformer(scale, factor=2))\n",
    "])\n",
    "pipeline.set_params(scaler__factor=10)\n",
    "pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more parameter grids over lists of `kw_args` dictionaries!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
